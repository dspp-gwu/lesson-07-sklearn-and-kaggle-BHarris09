{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn & Kaggle\n",
    "This week, we're going to learn about sci-kit learn.  For this lesson, I also want to introduce you to [Kaggle](https://www.kaggle.com/competitions) and its massive community of data scientists and learning materials.  Kaggle is a great place to get your feet wet with machine learning projects, and compare your approach to how others -- often hundreds of others -- have tackled the same problem.  \n",
    "\n",
    "For this exercise, we're going to walk through a Kaggle competition that is perfect for learning about scikit learn: The [Titanic Challenge](https://www.kaggle.com/c/titanic). \n",
    "\n",
    "## Lesson Plan\n",
    "\n",
    "1. The first step is to go to the site and learn a bit about the challenge: https://www.kaggle.com/c/titanic\n",
    "2. Once you've got a sense of what we're trying to do (predict whether a person will survive), we'll walk through the basics of loading our packages and data.  \n",
    "3. Then we'll spend a fair amount of time just looking at the data and gettting it into good shape for sklearn. \n",
    "4. Then we'll actually use sklearn and learn the basics.  You'll see pretty quickly why people use scikit learn -- it lets you try out many combinations of paremeters in many types of models with a simple set of commands. \n",
    "5. Then, we'll connect all our steps togehter into what sklearn calls a \"pipeline\". This will add a layer of complexity to our work, but will allow us to use something called \"grid search\" to train our model across the entire grid of possilbe features combintions and features weights for any classifier. \n",
    "5. Finally, once we have our pipeline up and running, we can submit it to Kaggle & officially join the data science community there. Don't worry, there is pretty much zero chance that we will win the competition.  But we will win a place in the heart of data science! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing \n",
    "\n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf \n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib  inline\n",
    "import seaborn as sns; sns.set(color_codes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A True Test\n",
    "Before we import out data, one important note: our test data set has no values for \"Survived\".  Yup, that rights.  And that's how it should be. We're going to build a model using our training data, then use that model to generate data for our test data.  This is a great real-world check.  We don't get to peak at the test data; we have to try to guess it from what know of the training data.  Bye bye traditional stats; hello machine learning & data science!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', header = 0, index_col = 'PassengerId')\n",
    "df_test = pd.read_csv('test.csv', header = 0, index_col = 'PassengerId')\n",
    "\n",
    "# I'm going to combine the two data sets for the purpose of data cleaning and feature generation.  \n",
    "# But I'm going to keep track of them by labelling them \"train\" and \"test\" in the multi-index key. \n",
    "# That way I can select them later by using 'df.loc['train]' and df.loc['test'].  \n",
    "# Multi-indexing is one of the ost powerful featurs of Pandas, and this is a perfect use for it. \n",
    "\n",
    "df = pd.concat([df_train, df_test], keys=[\"train\", \"test\"])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - grok the multi-index\n",
    "Now let's take a quick look at the data. just type \"df\" and see if you can see how the data is now organized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "\n",
    "OK, some of these fields look a little opaque.  What does SibSp mean?  To help with that, here's a data dictionary: \n",
    "\n",
    "```\n",
    "Data Dictionary\n",
    "Survived: Survival\t0 = No, 1 = Yes\n",
    "Pclass: Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "Sex: Sex\t\n",
    "Age: Age in years\n",
    "SibSp: # of siblings / spouses aboard the Titanic\n",
    "Parch: # of parents / children aboard the Titanic\n",
    "Ticket: Ticket number\n",
    "Fare: Passenger fare\n",
    "Cabin: Cabin number\n",
    "Embarked: Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "Variable Notes\n",
    "\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the data\n",
    "\n",
    "First, notice that Age and Fare are missing some values.  Let's fill those in.  There are much fancier ways to do this, but I'll just put in the median.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Fare'] = df['Fare'].fillna(df['Fare'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what about Name, Sex, Ticket, Cabin, and Embarked?  Those are text fields.  As such, they can't be managed numerically.  Which means we have to transform them into numbers if we want to use them. Let's see if we can clean these up a bit. \n",
    "\n",
    "- \"Name\", for example is just text.  We might try to transform that using some fancy algorithms, but let's leave that alone for now.  \n",
    "- \"Sex\" is a text field, too.  Let's turn that from a string into a one or a zero. \n",
    "- \"Embarked\" is also a text field, that should be turned into a set of dummy variables. \n",
    "- \"Pclass\" is a number, but it really should be a categorical variable fore each class. \n",
    "\n",
    "Let's do each right now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - pd.dummies\n",
    "\n",
    "Using pandas excellent 'get_dummies' method, we can transform each of these variables (Sex, Embarked, and Pclass) into dummy binary variables. The command is really simple. \n",
    "\n",
    "```pd.get_dummies(train, columns = ['Pclass'])```\n",
    "\n",
    "look up the documentation for that command, then see if you can return a dataframe that turns those three variables into dummies, while leaving the others intact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy, right? Let's do that for \"Pclass\", \"Sex\", and \"Embarked\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=['Pclass','Sex','Embarked'], drop_first=True).copy()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I added 'drop_first=True' as a parameter to the get_dummies command.  Why do you think I do that? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on feature generation\n",
    "\n",
    "The difference between a good model and a great model often depends on feature generation. Even when we just have a few variables like this, we can often generate hundreds of features from them by looking at various combinations.  For example, if we were really careful, we could probably figure out which passangers belong to which family and create a family ID.  Maybe members of smaller families do better than larger families, all other things being equal. Maybe single folks are more likely to survive because they are not held back by trying to save other family members.  Maybe members of families are more likely to survive because they are more motivated and can work together.  \n",
    "\n",
    "We're not going to spend time adding all these features, but if this were something like detecting malignant tumors or scheduling police -- or perhaps even more importantly, finding rats! -- we'd be generating as many features as we could plausibly come up with.  As you'll see in a bit, having too many features is not as serious a problem for sklearn as it is for traditional frequentist linear models like traditional regression. \n",
    "\n",
    "All that is to say that feature generation is very important.  Try your hand at generating some features below. Start with an easy one: family size. Or try more if you like! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eg, df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - Descriptive Statistics\n",
    "\n",
    "Now use ```train.describe()``` to examine your data again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['train'].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now use the ```.corr()``` method to get basic correlations with Survived. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Survived'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['train'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away, we can see a few things.  The people who were more likely to die were men, 3rd class passenger, and passengers who boarded at Southampton.  Conversely, women, first class passengers, and passengers who boarded at Cherbourgh were more likely to survive.  Also, we an see that fare price is positively correlated with survival.  \n",
    "\n",
    "If we were in the old world, just using statsmodels, we'd make a formula, maybe like this: \n",
    "\n",
    "```Survived ~ Sex_female * Parch + Pclass_1 + Fare + Embarked_C + SibSp```\n",
    "\n",
    "And then we'd feed that model into a logistic regression. Then we'd develop our various intuitions by playing around with the model on our training set, adding, subtracting, and interacting variables in the linear equation. Then we'd make some informed hypotheses about the relationships in the data and test them on a validation data set. And finally, when had our sense that we really knew what was going on, we test our best models on the test set. \n",
    "\n",
    "But we're entering the world of data science and machine learning. We're going to become more and more rigorous about automating all of that, and far more agnostic about our feaures and models.  We'll work hard to develop good features for our model, but once we do that, we want to try to take the human out of the loop of manipulating and comparing models.  We'll turn running through all those features and models over to sklearn, and just give it a way to evaluate and compare them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn\n",
    "\n",
    "The first thing we need to do is turn our training data into two matrices of equal length, one called \"X\" with our features, and the other called \"Y\" with our dependent variable (oddly, in the ML world, the y variable is often called your \"labels\"). \n",
    "\n",
    "## preparing our data\n",
    "\n",
    "First, we'll make a data set without columns we're not using at the moment. (Please remember that you probably *can* and *should* use them when doing thorough feature generation.we're just not doing now for the sake of simplicity.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tv = df.drop(['Cabin', 'Name', 'Ticket'], axis=1).copy().dropna()\n",
    "tv = df_tv.loc['train']\n",
    "X = tv.drop('Survived',  axis=1).as_matrix()\n",
    "y = tv['Survived'].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn doesn't read pandas dataframes -- instead it takes numpy matrices.  Let's compare what they look like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Just lists of numbers in brackets.  Yup.  No labels.  That's why we wait until the very end to switch over to numpy matrices.  Pandas is way, way friendlier. \n",
    "\n",
    "## Create a validation set. \n",
    "\n",
    "This may be a bit confusing, but validation is really just another word for a pre-test test. And since sklearn really only has labels for train and test, that's what we'll use here. Just think of it as our validation set. \n",
    "\n",
    "To split our data, I'm going to use the sklearn method designed for this and helpfully named 'train_test_split'. I'm going to split these 50-50, though as data sets get larger, the splits can be more like 80-20 or 90-10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate = sklearn.model_selection.train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have four matrices, X and y for training, and X and y for validating. \n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "My next goal is to figure out which features to use.  If we look at our feature set now, we can see we have 9 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not a lot; what if we had 1,000?  or 100,000?   To address this, we'd use the SelectKBest command, which allows us to select the number of features we want. By default, \"best\" uses anova classification fit statistics, though it can be changed if we want; but that's not import right now -- it's a good default. \n",
    "\n",
    "Let's try select 5 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = sklearn.feature_selection.SelectKBest(k=5).fit_transform(X_train, y_train)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll automate more of this later, but holy-moly that was fast.  And easy.  Now I can have whatever number of features make sense for my particular use case.  Yay! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, predicting and evaluating. \n",
    "\n",
    "Now we can train our model on the test data.  We can use just about any classifier we want -- logistic regression, random forest, you name it. Let's start with what is one of the most common classifiers in machine learning: familiar old logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression()  # describe our model\n",
    "train_fit = clf.fit(X_train, y_train)            # train our model\n",
    "y_prediction = train_fit.predict(X_validate)         # use our model to predict y varialbe for out validation data\n",
    "y_prediction   # take a look at our validation predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ROC -- evaluating our model\n",
    "\n",
    "Now we can evaluate how we did. The most common statistic for evaluating classifcation is the ROC, or the \"Receiver Operator Curve\".  It tells us how often we get false positives relative to true postivies. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_validate, y_prediction)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc['test'].drop(['Cabin', 'Name', 'Ticket'], axis=1)\n",
    "X_test = df_test.drop('Survived',  axis=1).as_matrix()\n",
    "y_test = train_fit.predict(X_test)         # use our model to predict y varialbe for out validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just save it to upload to Kaggle.  Kaggle expects integers and a header row, so we'll give them that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['test','Survived'] = y_test\n",
    "df.loc['test','Survived'].astype(int).to_csv('results.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it! \n",
    "\n",
    "We'll stop there for now.  \n",
    "\n",
    "Go and upload your results to Kaggle. Then see if you can improve your score!  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
